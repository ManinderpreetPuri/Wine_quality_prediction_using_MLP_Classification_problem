{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab02b solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "5fsCX5JKBvKu"
      },
      "source": [
        "Pytorch Basics\n",
        "\n",
        "In this notebook we will convert the problem we solved usnig regression notebook into a classification problem instead. So we will assign each wine quality rating to a different class. So quality of 0 will belong to a different class to quality of 1.\n",
        "\n",
        "\n",
        "The biggest difference between a regression solution and multi-class classification in terms of implementation is that now our model needs to output 10 values (1 for each quality rating) instead of just a single output. Also we will need to change our loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8AJW2PhBvNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a1404f4-028e-4365-e455-2c475feacb6f"
      },
      "source": [
        "# Import Pandas\n",
        "import pandas as pd\n",
        "\n",
        "# There are two datasets available, but we'll just work with the larger, white\n",
        "# wine dataset. Feel free to play around with the red wine dataset.\n",
        "red_wine_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
        "white_wine_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
        "\n",
        "# It's a single function call to load a dataset. CSV files typically use commas\n",
        "# as delimiters between records, but our dataset uses semicolons so we had to\n",
        "# specify it with the \"delimiter\" argument.\n",
        "all_data = pd.read_csv(white_wine_url, delimiter=';')\n",
        "\n",
        "print(type(all_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcEDRSKjrI18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ab6ef5-e545-403c-caf3-749fc077c80d"
      },
      "source": [
        "target_column = \"quality\"\n",
        "\n",
        "# TODO: Extract just the *input* features. Instead of specifying all of the features we\n",
        "# want, we should drop the feature we *don't* want.\n",
        "# x_data = ...\n",
        "\n",
        "# SOLUTION LINE\n",
        "x_data = all_data.drop(target_column, axis=1)\n",
        "\n",
        "# TODO: Extract the target feature. We don't want a Series here, but a DataFrame\n",
        "# with one column (see the above cell)\n",
        "# y_data = ...\n",
        "\n",
        "# SOLUTION LINE\n",
        "y_data = all_data[[target_column]]\n",
        "\n",
        "# If your implementation is correct the shape of y_data should be (4898, 1)\n",
        "# So y_data is a 2D tensor containing 4898 examples and just 1 feature.\n",
        "print(\"y_data shape:\", y_data.shape) \n",
        "\n",
        "# Just like with tensors, we can print the shape\n",
        "num_examples = x_data.shape[0]\n",
        "num_input_features = x_data.shape[1]\n",
        "\n",
        "# If your implementation is correct the number of samples should be 4898\n",
        "print(\"Number of examples:\", num_examples) \n",
        "\n",
        "# If your implementation is correct the number of input features should be 11\n",
        "print(\"Number of input features:\", num_input_features)\n",
        "\n",
        "# If your implementation the shape of the x_data tensor should be (4898, 11)\n",
        "# which means it is a 2D array where each row represents one example and each\n",
        "# column represents one feature\n",
        "print(\"x_data shape:\", x_data.shape )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_data shape: (4898, 1)\n",
            "Number of examples: 4898\n",
            "Number of input features: 11\n",
            "x_data shape: (4898, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4dK-21abmtk"
      },
      "source": [
        "# Import Torch and the dataset utilities we need\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split\n",
        "\n",
        "# The percentages for each partition\n",
        "TRAIN_SPLIT = 0.8\n",
        "VAL_SPLIT = 0.1\n",
        "TEST_SPLIT = 0.1\n",
        "# Ensure that the splits add to 100%\n",
        "assert TRAIN_SPLIT + VAL_SPLIT + TEST_SPLIT == 1\n",
        "\n",
        "\n",
        "# TODO: Create two tensors and initialise them with x_data.values and y_data.values.\n",
        "# The dtype should be torch.float32. DataFrame.values directly returns the 2D\n",
        "# data in the dataframe, which is what Torch requires to initialise a tensor.\n",
        "# x_tensor = ...\n",
        "# y_tensor = ...\n",
        "\n",
        "# SOLUTION LINE\n",
        "x_tensor = torch.tensor(x_data.values, dtype=torch.float32)\n",
        "# SOLUTION LINE\n",
        "y_tensor = torch.tensor(y_data.values, dtype=torch.float32)\n",
        "\n",
        "# Now we construct a TensorDataset - a simple class used to associate each x and\n",
        "# y value in our tensors.\n",
        "full_dataset = TensorDataset(x_tensor, y_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX2E5L1Fx3p3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7737b4f7-b65e-441f-8663-9247bd1cb0e0"
      },
      "source": [
        "# Calculate the number of examples in each partition\n",
        "train_size = int(TRAIN_SPLIT * len(all_data))\n",
        "val_size = int(VAL_SPLIT * len(all_data))\n",
        "test_size = len(all_data) - train_size - val_size\n",
        "\n",
        "print(\"Train examples:     \", train_size)\n",
        "print(\"Validation examples:\", val_size)\n",
        "print(\"Test examples:      \", test_size)\n",
        "\n",
        "# Before we actually split the dataset, we seed Torch's random number generator.\n",
        "# This ensure that we end up with the exact same partitions every time it's run.\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# TODO: Split the dataset using the random_split function we imported earlier.\n",
        "# The function takes a dataset and a list of partition lengths.\n",
        "# Hint: We already have all of these variables available\n",
        "# train_dataset, val_dataset, test_dataset = random_split(...)\n",
        "\n",
        "# SOLUTION LINE\n",
        "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train examples:      3918\n",
            "Validation examples: 489\n",
            "Test examples:       491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3NZrKhIeTvB"
      },
      "source": [
        "# When you've finished the lab, try modifying the batch size to see what effect\n",
        "# it has on your results\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# TODO: Construct a DataLoader for each Dataset. The constructor takes three\n",
        "# arguments - a Dataset, the batch size, and a boolean indicating whether it\n",
        "# should shuffled. We will set shuffle=True for train dataloader.\n",
        "\n",
        "# train_loader = DataLoader(...\n",
        "# val_loader = DataLoader(...\n",
        "# test_loader = DataLoader(...\n",
        "\n",
        "# SOLUTION LINE\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "# SOLUTION LINE\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "# SOLUTION LINE\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojUURBDh9-hm"
      },
      "source": [
        "### Enable GPU Training *(if available)*\n",
        "The rise in popularity of deep learning is largely a result of the availability of good Graphics Processing Units. So although it's not required, it's definitely good to utilise a GPU if you can.\n",
        "\n",
        "It's exceptionally easy to use a compatible GPU in Pytorch - we can do it in just a few lines of code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2co2qquU7lcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7461c90c-2880-4a29-9a35-dea2e637c796"
      },
      "source": [
        "# By default we'll assume that GPU acceleration isn't available\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# Check if GPU acceleration is available (requires a CUDA-compatible GPU) and\n",
        "# set the device variable accordingly. If the computer has more than one GPU,\n",
        "# you can specify which one by replacing 0 with a different index\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "\n",
        "print(\"Training on\", device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRbspMJc-Egx"
      },
      "source": [
        "### Define the Model\n",
        "Here you will need to change the MLP so that it outputs 10 features instead of just 1. Since to perform classification we need to output a value for each of the 10 quality classes (from 0 to 9)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM8YqMMz0kCE"
      },
      "source": [
        "# Import the neural network module of Pytorch. We access its methods like \"nn.Linear\"\n",
        "import torch.nn as nn\n",
        "\n",
        "# Our model class must subclass nn.Module\n",
        "class MLP(nn.Module):\n",
        "    # The __init__ method is similar to a constructor like you find in other\n",
        "    # languages. We will take the device as an argument to transfer the model to the GPU\n",
        "    def __init__(self, device):\n",
        "        super().__init__()\n",
        "        # TODO: Initialise a Sequential module consisting of the below layers, and\n",
        "        # store it in the member variable self.seq\n",
        "        #  - a linear layer mapping from num_input_features to 20 hidden features\n",
        "        #  - a ReLU activation layer\n",
        "        #  - a linear layer mapping from 20 hidden features to a 10 features (the wine quality)\n",
        "        # You can look here for an example:\n",
        "        #     https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html\n",
        "        # self.seq = nn.Sequential(...\n",
        "\n",
        "        # SOLUTION LINE\n",
        "        self.seq = nn.Sequential(nn.Linear(num_input_features, 20),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Linear(20, 10))\n",
        "    \n",
        "        # The model stays on the CPU by default. Calling the \"to\" method transfers\n",
        "        # the model weights to whichever device we specified\n",
        "        self.to(device)\n",
        "\n",
        "    # Our forward method simply takes the input batch x, passes it through our\n",
        "    # Sequential module, and returns the outputs (predictions)\n",
        "    def forward(self, x):\n",
        "        return self.seq(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q8gRMgJQVJP"
      },
      "source": [
        "## Function that can be used to compute accuracy\n",
        "The function below can be used to compute the accuracy of classification. Note it looks at each of the predicted features (in our case that is the 10 quality values) and picks the largest feature to represented the predicted class (predicted quality value). The largest feature is represented by its index in the output feature tensor. Then it compares the predicted index against the target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoaKBx3RQaZy"
      },
      "source": [
        "def compute_accuracy(predictions, targets):\n",
        "    # Find the index with the highest predicted value - this is the predicted digit\n",
        "    predictions = predictions.argmax(1)\n",
        "    # Count the number of predictions that match the target\n",
        "    correct = (predictions == targets).sum().item()\n",
        "    # Compute the accuracy as the percentage correctly predicted\n",
        "    acc = correct / len(targets)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVlR_DGsuITZ"
      },
      "source": [
        "## Simple Training loop\n",
        "\n",
        "You will need to make the following changes to make it work for classification:\n",
        "\n",
        "\n",
        "1.   Change the <font color=red>loss</font> function to <font color=red>nn.CrossEntropyLoss()</font>.\n",
        "2.   Currently the labels are 2D tensors of shape \\[Batch size, 1\\] we need to change it to 1D tensors of shape \\[Batch size\\]. We can do this using the squeeze function (<font color=red>torch.squeeze(tensor_name)</font>). \n",
        "3.   Currently the labels have float32 type. We need to change it to type long to make it work for classification. The way to convert a tensor into a type long is to use the long function (<font color=red>tensor_name.long()</font>). \n",
        "4.   Call the compute_accuracy function to compute the classification accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjR6AGaWvV85",
        "outputId": "d5420bbc-5115-4c56-c5e7-f8f794beaebf"
      },
      "source": [
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# TODO: Change this loss to use the correct loss for classification\n",
        "#criterion = nn.MSELoss()\n",
        "\n",
        "#SOLUTION\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use MLP as the model\n",
        "model = MLP(device)\n",
        "# Use the SGD optimizer with initial learning rate set to 0.0001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
        "# The number of times we loop over the entire dataset\n",
        "total_epochs = 100\n",
        "\n",
        "\n",
        "for epoch in range(total_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    epoch_train_accuracy = []\n",
        "\n",
        "    # The following is computed in a single pass through the dataset\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # TODO: Write here code that coverts the labels tensor from shape [batchsize, 1] to shape [batchsize]\n",
        "        #       Next write code that converts the labels tensor to type long().\n",
        "        #       labels = ....\n",
        "        #       labels = ....\n",
        "\n",
        "        # Solution\n",
        "        labels = torch.squeeze(labels).long()\n",
        "\n",
        "        # Copy the data to the specified device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss using the loss function\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # TODO: write code here for computing the classification accuracy\n",
        "        #       by calling the compute_accuracy function written in the previous \n",
        "        #       cell.\n",
        "        #       accuracy = ....\n",
        "\n",
        "        # solution \n",
        "        accuracy = compute_accuracy(outputs, labels)\n",
        "        epoch_train_accuracy.append(accuracy)\n",
        "\n",
        "        # Perform backprop using the loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "     # print statistics\n",
        "    print('epoch: %d loss: %.3f' % (epoch + 1, running_loss / len(train_loader)))\n",
        "    print('epoch: %d accuracy: %.3f' % (epoch + 1, np.mean(epoch_train_accuracy)))\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 loss: 6.389\n",
            "epoch: 1 accuracy: 0.146\n",
            "epoch: 2 loss: 1.910\n",
            "epoch: 2 accuracy: 0.320\n",
            "epoch: 3 loss: 1.841\n",
            "epoch: 3 accuracy: 0.326\n",
            "epoch: 4 loss: 1.755\n",
            "epoch: 4 accuracy: 0.335\n",
            "epoch: 5 loss: 1.700\n",
            "epoch: 5 accuracy: 0.331\n",
            "epoch: 6 loss: 1.615\n",
            "epoch: 6 accuracy: 0.343\n",
            "epoch: 7 loss: 1.561\n",
            "epoch: 7 accuracy: 0.347\n",
            "epoch: 8 loss: 1.510\n",
            "epoch: 8 accuracy: 0.346\n",
            "epoch: 9 loss: 1.462\n",
            "epoch: 9 accuracy: 0.360\n",
            "epoch: 10 loss: 1.430\n",
            "epoch: 10 accuracy: 0.362\n",
            "epoch: 11 loss: 1.418\n",
            "epoch: 11 accuracy: 0.370\n",
            "epoch: 12 loss: 1.400\n",
            "epoch: 12 accuracy: 0.380\n",
            "epoch: 13 loss: 1.395\n",
            "epoch: 13 accuracy: 0.376\n",
            "epoch: 14 loss: 1.384\n",
            "epoch: 14 accuracy: 0.383\n",
            "epoch: 15 loss: 1.390\n",
            "epoch: 15 accuracy: 0.388\n",
            "epoch: 16 loss: 1.381\n",
            "epoch: 16 accuracy: 0.391\n",
            "epoch: 17 loss: 1.373\n",
            "epoch: 17 accuracy: 0.394\n",
            "epoch: 18 loss: 1.366\n",
            "epoch: 18 accuracy: 0.399\n",
            "epoch: 19 loss: 1.357\n",
            "epoch: 19 accuracy: 0.398\n",
            "epoch: 20 loss: 1.355\n",
            "epoch: 20 accuracy: 0.403\n",
            "epoch: 21 loss: 1.348\n",
            "epoch: 21 accuracy: 0.420\n",
            "epoch: 22 loss: 1.352\n",
            "epoch: 22 accuracy: 0.419\n",
            "epoch: 23 loss: 1.342\n",
            "epoch: 23 accuracy: 0.422\n",
            "epoch: 24 loss: 1.340\n",
            "epoch: 24 accuracy: 0.419\n",
            "epoch: 25 loss: 1.336\n",
            "epoch: 25 accuracy: 0.424\n",
            "epoch: 26 loss: 1.333\n",
            "epoch: 26 accuracy: 0.426\n",
            "epoch: 27 loss: 1.332\n",
            "epoch: 27 accuracy: 0.434\n",
            "epoch: 28 loss: 1.325\n",
            "epoch: 28 accuracy: 0.436\n",
            "epoch: 29 loss: 1.322\n",
            "epoch: 29 accuracy: 0.442\n",
            "epoch: 30 loss: 1.326\n",
            "epoch: 30 accuracy: 0.444\n",
            "epoch: 31 loss: 1.316\n",
            "epoch: 31 accuracy: 0.440\n",
            "epoch: 32 loss: 1.317\n",
            "epoch: 32 accuracy: 0.445\n",
            "epoch: 33 loss: 1.323\n",
            "epoch: 33 accuracy: 0.450\n",
            "epoch: 34 loss: 1.315\n",
            "epoch: 34 accuracy: 0.449\n",
            "epoch: 35 loss: 1.311\n",
            "epoch: 35 accuracy: 0.453\n",
            "epoch: 36 loss: 1.316\n",
            "epoch: 36 accuracy: 0.451\n",
            "epoch: 37 loss: 1.304\n",
            "epoch: 37 accuracy: 0.458\n",
            "epoch: 38 loss: 1.303\n",
            "epoch: 38 accuracy: 0.457\n",
            "epoch: 39 loss: 1.303\n",
            "epoch: 39 accuracy: 0.457\n",
            "epoch: 40 loss: 1.300\n",
            "epoch: 40 accuracy: 0.458\n",
            "epoch: 41 loss: 1.295\n",
            "epoch: 41 accuracy: 0.467\n",
            "epoch: 42 loss: 1.304\n",
            "epoch: 42 accuracy: 0.456\n",
            "epoch: 43 loss: 1.294\n",
            "epoch: 43 accuracy: 0.461\n",
            "epoch: 44 loss: 1.298\n",
            "epoch: 44 accuracy: 0.464\n",
            "epoch: 45 loss: 1.298\n",
            "epoch: 45 accuracy: 0.457\n",
            "epoch: 46 loss: 1.301\n",
            "epoch: 46 accuracy: 0.463\n",
            "epoch: 47 loss: 1.292\n",
            "epoch: 47 accuracy: 0.457\n",
            "epoch: 48 loss: 1.284\n",
            "epoch: 48 accuracy: 0.467\n",
            "epoch: 49 loss: 1.296\n",
            "epoch: 49 accuracy: 0.455\n",
            "epoch: 50 loss: 1.289\n",
            "epoch: 50 accuracy: 0.465\n",
            "epoch: 51 loss: 1.282\n",
            "epoch: 51 accuracy: 0.467\n",
            "epoch: 52 loss: 1.280\n",
            "epoch: 52 accuracy: 0.475\n",
            "epoch: 53 loss: 1.282\n",
            "epoch: 53 accuracy: 0.465\n",
            "epoch: 54 loss: 1.281\n",
            "epoch: 54 accuracy: 0.462\n",
            "epoch: 55 loss: 1.277\n",
            "epoch: 55 accuracy: 0.469\n",
            "epoch: 56 loss: 1.276\n",
            "epoch: 56 accuracy: 0.467\n",
            "epoch: 57 loss: 1.278\n",
            "epoch: 57 accuracy: 0.460\n",
            "epoch: 58 loss: 1.275\n",
            "epoch: 58 accuracy: 0.467\n",
            "epoch: 59 loss: 1.274\n",
            "epoch: 59 accuracy: 0.474\n",
            "epoch: 60 loss: 1.271\n",
            "epoch: 60 accuracy: 0.470\n",
            "epoch: 61 loss: 1.282\n",
            "epoch: 61 accuracy: 0.458\n",
            "epoch: 62 loss: 1.277\n",
            "epoch: 62 accuracy: 0.468\n",
            "epoch: 63 loss: 1.272\n",
            "epoch: 63 accuracy: 0.472\n",
            "epoch: 64 loss: 1.272\n",
            "epoch: 64 accuracy: 0.468\n",
            "epoch: 65 loss: 1.277\n",
            "epoch: 65 accuracy: 0.462\n",
            "epoch: 66 loss: 1.274\n",
            "epoch: 66 accuracy: 0.474\n",
            "epoch: 67 loss: 1.272\n",
            "epoch: 67 accuracy: 0.465\n",
            "epoch: 68 loss: 1.267\n",
            "epoch: 68 accuracy: 0.466\n",
            "epoch: 69 loss: 1.274\n",
            "epoch: 69 accuracy: 0.459\n",
            "epoch: 70 loss: 1.269\n",
            "epoch: 70 accuracy: 0.467\n",
            "epoch: 71 loss: 1.271\n",
            "epoch: 71 accuracy: 0.463\n",
            "epoch: 72 loss: 1.268\n",
            "epoch: 72 accuracy: 0.470\n",
            "epoch: 73 loss: 1.267\n",
            "epoch: 73 accuracy: 0.462\n",
            "epoch: 74 loss: 1.267\n",
            "epoch: 74 accuracy: 0.464\n",
            "epoch: 75 loss: 1.271\n",
            "epoch: 75 accuracy: 0.468\n",
            "epoch: 76 loss: 1.262\n",
            "epoch: 76 accuracy: 0.474\n",
            "epoch: 77 loss: 1.267\n",
            "epoch: 77 accuracy: 0.472\n",
            "epoch: 78 loss: 1.263\n",
            "epoch: 78 accuracy: 0.467\n",
            "epoch: 79 loss: 1.260\n",
            "epoch: 79 accuracy: 0.472\n",
            "epoch: 80 loss: 1.264\n",
            "epoch: 80 accuracy: 0.460\n",
            "epoch: 81 loss: 1.262\n",
            "epoch: 81 accuracy: 0.469\n",
            "epoch: 82 loss: 1.260\n",
            "epoch: 82 accuracy: 0.465\n",
            "epoch: 83 loss: 1.264\n",
            "epoch: 83 accuracy: 0.466\n",
            "epoch: 84 loss: 1.258\n",
            "epoch: 84 accuracy: 0.470\n",
            "epoch: 85 loss: 1.266\n",
            "epoch: 85 accuracy: 0.466\n",
            "epoch: 86 loss: 1.259\n",
            "epoch: 86 accuracy: 0.468\n",
            "epoch: 87 loss: 1.263\n",
            "epoch: 87 accuracy: 0.467\n",
            "epoch: 88 loss: 1.267\n",
            "epoch: 88 accuracy: 0.468\n",
            "epoch: 89 loss: 1.270\n",
            "epoch: 89 accuracy: 0.462\n",
            "epoch: 90 loss: 1.268\n",
            "epoch: 90 accuracy: 0.474\n",
            "epoch: 91 loss: 1.257\n",
            "epoch: 91 accuracy: 0.468\n",
            "epoch: 92 loss: 1.257\n",
            "epoch: 92 accuracy: 0.463\n",
            "epoch: 93 loss: 1.260\n",
            "epoch: 93 accuracy: 0.468\n",
            "epoch: 94 loss: 1.265\n",
            "epoch: 94 accuracy: 0.459\n",
            "epoch: 95 loss: 1.255\n",
            "epoch: 95 accuracy: 0.469\n",
            "epoch: 96 loss: 1.255\n",
            "epoch: 96 accuracy: 0.478\n",
            "epoch: 97 loss: 1.263\n",
            "epoch: 97 accuracy: 0.466\n",
            "epoch: 98 loss: 1.256\n",
            "epoch: 98 accuracy: 0.467\n",
            "epoch: 99 loss: 1.260\n",
            "epoch: 99 accuracy: 0.465\n",
            "epoch: 100 loss: 1.258\n",
            "epoch: 100 accuracy: 0.472\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkWu_koZTbHb"
      },
      "source": [
        "<font color = red> Isn't it so much cooler to see an accuracy measure rather than just loss! It actually lets us know how close we are to 100%. This is one of the benefits of doing classification rather than regression. There is no clear accuracy metric for regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_4VO_ZI6h8c"
      },
      "source": [
        "## Simple Testing loop\n",
        "\n",
        "Now modify the testing loop so that is also works for classification. Do all the things you did for the training loop with the exception of changing the loss function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crJwn4Z56iTE",
        "outputId": "50b3e697-c944-49e2-fc2c-6955b024f245"
      },
      "source": [
        "running_loss = 0.0\n",
        "total_test_accuracy = []\n",
        "\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "   # get the inputs; data is a list of [inputs, labels]\n",
        "   inputs, labels = data\n",
        "  \n",
        "   # TODO: Write here code that coverts the labels tensor from shape [batchsize, 1] to shape [batchsize]\n",
        "   #       Next write code that converts the labels tensor to type long().\n",
        "   #       labels = ...\n",
        "   #       labels = ...\n",
        "\n",
        "   # Solution\n",
        "   labels = torch.squeeze(labels).long()\n",
        "\n",
        "   # Copy the data to the specified device\n",
        "   inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "   model.eval()\n",
        "   with torch.no_grad():\n",
        "    # Forward + backward + optimize\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # Compute the loss using the loss function\n",
        "    loss = criterion(outputs, labels)\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    # TODO: write code here for computing the classification accuracy\n",
        "    #       by calling the compute_accuracy function\n",
        "    #       accuracy = ....\n",
        "    \n",
        "    # Solution\n",
        "    accuracy = compute_accuracy(outputs, labels)\n",
        "    \n",
        "    total_test_accuracy.append(accuracy) \n",
        "\n",
        "print(\"test loss: \", running_loss/len(test_loader))\n",
        "print('test accuracy: ', np.mean(total_test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test loss:  1.19777350127697\n",
            "test accuracy:  0.48187681686046513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAc35TPd4joF"
      },
      "source": [
        "### Make the results better!\n",
        "Look at some of the things you tried for improving the regression problem result and see how well they work for classification. What is the highest classification accuracy you can get? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuigNCdraELY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}